####  General Parameters  ####
year: '2017'
source_path: 'data/source'
result_path: 'results'
db_path: "./results/db/2017"
output_dir_name: 'ml_models'
mapping_path: 'resources/appendices/2017_mapping.csv'
error_analisys: True
experimant_name: 'pipline_experiment'
domain: 'drugs'

####  Preprocessing Flow  ####
prepare_to_tagging: False #Should I also produce a json file, in preparation for tagging later?

#### Predict Setence Classfiers Flow ####
classifiers_path: /sise/home/ezradin/moj_models/09_01_second_level_prediction
first_lvl_cls_path: /home/ezradin/pred-sentencing/results/evaluations/sentence_calssification/08_31_just_first_level_1epoch
# first_lvl_cls_path: "/sise/home/ezradin/moj/finetuning_models/"

test_set_path: resources/data/trainning/sentence_classification/12cases_in_train

case_dir_path: resources/data_mock/db/1316-04-19 #Path to the folder where the document is stored
preprocess_file_path: results/db/1316-04-19/preprocessing.csv
threshold: 0.95 # The threshold for each classifie (can determine different threshold for each cls in 
                # classifie config)


#### Feature Extraction Flow ####
model_name:  dicta-il/dictalm2.0-instruct  # model name for Q&A model - ['tdklab/hebert-finetuned-hebrew-squad', 'claude', 'dicta-il/dictabert-heq', 'dicta-il/dictalm2.0-instruct', 'CohereForAI/c4ai-command-r-v01-4bit']
qa_extraction_flag: true             # True if you want to extract by QA method
regex_extraction_flag: false
api_key: ""         # True if you want to extract by regex method
db_flow: False


#### Feature Similarity Flow ####
feature_similarity:
  embedding_model_name: claude #"dicta-il/dictabert"
  fe_df_path: results/db/SH-16-01-21459-8/regex_features_extracted.csv
  feature_association_path: resources/appendices/feature_association.yaml

#### Predict Similarity Docs Flow ####
model_path: resources/models/Decision_Tree_Metrics_features_embd_qa_F1_0.738.pkl
pairs_similarity_path: results/pairs_similarity/2024-04-09-14:50_rgx_din_test/test.csv


#### Pairs Similarity Creation ####
pairs_similarity:
  features_type: qa
  label_type: Tagged Label
  tagged_pairs_path: /home/ezradin/pred-sentencing/resources/data/tagging/gt/similarity_paris.csv
  embeddding_features_path: results/embedding/fearture_regex_emb.xlsx
  create_more_data: False
  feature_from_tagged: True
  predict_path: #/home/ezradin/pred-sentencing/predicts_similarity_cases_on_tagged.pkl

#### Feature embedding ####
feature_embedding:
  embedding_model_name: dicta-il/dictabert
  manual_tagging_path: resources/data_mock/information_extraction/weapon/2017/feature_extraction_taggers.csv
  extraction_methods: ['qa', 'regex'] #you can choose from one/few from the options - ['manual', 'qa', 'regex']


#### Training Similarity Case  ####
models_type: LLM #['random_forest'] # on or more from this types - ['random_forest', 'logistic_regression', 'decision_tree', 'svm']
loocv: False # Whether to use Leave-One-Out Cross-Validation (default: False)
seed: 42
binary_label: True
prompt_path: resources/prompts/case_simlarity.txt

#evaluation
test_path: C:/Users/max_b/PycharmProjects/moj_sl/pred-sentencing/resources/data/new_data/train_test/second_lvl/test.csv
eval: False