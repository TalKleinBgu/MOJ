# ---------- Most important is to change the experiment name!!'
experiment_name: 'second_level_prediction'
username: ezradin

#paths
data_path: "/home/{username}/pred-sentencing/resources/data/trainning/sentence_classification/12cases_in_train"
# data_path: '/home/ezradin/pred-sentencing/results/sentence_generation/combained/dfs'
result_path: '/home/{username}/pred-sentencing/results'

# save_dir: '/home/ezradin/pred-sentencing/results/evaluations/sentence_calssification/'
save_dir: '/home/{username}/moj_models'


generated_data: False
setfit_din_v: True
balance: True #balance the train set
save_model: true #if False, save just the result by label 
load_xlsx: true
just_first_level: false

labels:            # What classifiers would we like to train

  - CIR_STATUS_WEP
  # - CIR_HELD_WAY_WEP
  # - CIR_PURPOSE

  # - CIR_AMMU_AMOUNT_WEP
  # - CIR_OBTAIN_WAY_WEP
  # - CIR_BUYER_ID_WEP
  # - CIR_TYPE_WEP
  # - CIR_MONEY_PAID_WEP
  # - POSSESSION_WEP
      # - CIR_USE
  # - CONFESSION
  # - CIR_PLANNING

models_to_train:
  - t-few: false
  - roberta: false
  - setfit: true

model_name_initial: test 
all_class: true

#model param
num_epoch: 5
# num_samples_list: [50,20,50,50,10] #How many samples would we like to take from each classifier respectively, the length of the list is required to be the same as labels_,
# batch_size: 16
# num_iteration: 5
pretrained_model : "amberoad/bert-multilingual-passage-reranking-msmarco"

pretrained_model_list:
    #  - HeNLP/HeRo
    #  - amberoad/bert-multilingual-passage-reranking-msmarco
    #  - dicta-il/dictabert
    #  - avichr/Legal-heBERT
    #  - avichr/heBERT
    #  - onlplab/alephbert-base

first_label_list:
  - CONFESSION
  - GENERAL_CIRCUM
  - PUNISHMENT
  - CIRCUM_OFFENSE
  - reject
