# Most important is to change the experiment name!!'
experiment_name: 'with_f2_try'
username: tak

# paths
data_path: "/home/{username}/MOJ/resources/data/trainning/sentence_classification/weapon/stratify_sentences"
save_dir: '/home/{username}/MOJ/results'
save_model_path: '/home/{username}/moj_models'

# models to train
models_to_train:
  - t-few: false
  - roberta: false
  - setfit: true

# which version to train
generated_data: False
setfit: True
balance: True # balance the train set
save_model: True #if False, save just the result by label 

#first level labels
first_label_list:
  # - CONFESSION
  - GENERAL_CIRCUMs
  # - PUNISHMENT
  # - CIRCUM_OFFENSE
  # - reject


#second level labels
second_label_list: 
  - CIR_STATUS_WEP
  # - CIR_HELD_WAY_WEP
  # - CIR_PURPOSE
  # - CIR_AMMU_AMOUNT_WEP
  # - CIR_OBTAIN_WAY_WEP
  # # - CIR_BUYER_ID_WEP
  # - CIR_TYPE_WEP
  # - CIR_MONEY_PAID_WEP
  # -  CIR_USE
  #  CIR_PLANNING
  # - RESPO
  # - REGRET


#labels to ignore
ignore_labels:
  - "Unnamed: 0"
  - verdict
  - text
  - CIR_BUYER_ID_WEP


pretrained_model_list:
    #  - HeNLP/HeRo
    #  - amberoad/bert-multilingual-passage-reranking-msmarco
     - dicta-il/dictabert
    #  - avichr/Legal-heBERT
     - avichr/heBERT
    #  - onlplab/alephbert-base
  

# training arguments
training_args:
  batch_size: 64
  body_learning_rate:
    - 0.00002
    - 0.000005
  head_learning_rate: 0.002
  l2_weight: 0.01
  num_epochs: 3 
  end_to_end: True
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  eval_steps: 3
  load_best_model_at_end: True








#for default version param
model_name_initial: test 
all_class: true
load_xlsx: true
num_epoch: 5
# num_samples_list: [50,20,50,50,10] #How many samples would we like to take from each classifier respectively, the length of the list is required to be the same as labels_,
# batch_size: 16
# num_iteration: 5
pretrained_model : "amberoad/bert-multilingual-passage-reranking-msmarco"

